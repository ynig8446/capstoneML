{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we apply RobustScaler to both transformed and non-transformed versions of our dataset.\n",
    "RobustScaler is particularly suitable when our features contain outliers, as it scales data using the interquartile range (IQR) instead of the mean and standard deviation.\n",
    "\n",
    "We fit only on the training set to avoid data leakage.\n",
    "\n",
    "The same scaler is used to transform validation and test sets accordingly.\n",
    "\n",
    "This setup allows us to later compare the effect of feature transformation (log1p) versus simple outlier-resistant scaling on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train_transform = pd.read_csv(\"../../data/processed/transformed/X_train_transform.csv\")\n",
    "X_val_transform = pd.read_csv(\"../../data/processed/transformed/X_val_transform.csv\")\n",
    "X_test_transform = pd.read_csv(\"../../data/processed/transformed/X_test_transform.csv\")\n",
    "\n",
    "X_train_no_transform = pd.read_csv(\"../../data/processed/no_transformed/X_train_no_transform.csv\")\n",
    "X_val_no_transform = pd.read_csv(\"../../data/processed/no_transformed/X_val_no_transform.csv\")\n",
    "X_test_no_transform = pd.read_csv(\"../../data/processed/no_transformed/X_test_no_transform.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup ---\n",
    "scaler_transform = RobustScaler()\n",
    "scaler_no_transform = RobustScaler()\n",
    "\n",
    "# --- 1. Fit only on training sets ---\n",
    "X_train_transform_scaled = scaler_transform.fit_transform(X_train_transform)\n",
    "X_val_transform_scaled = scaler_transform.transform(X_val_transform)\n",
    "X_test_transform_scaled = scaler_transform.transform(X_test_transform)\n",
    "\n",
    "X_train_no_transform_scaled = scaler_no_transform.fit_transform(X_train_no_transform)\n",
    "X_val_no_transform_scaled = scaler_no_transform.transform(X_val_no_transform)\n",
    "X_test_no_transform_scaled = scaler_no_transform.transform(X_test_no_transform)\n",
    "\n",
    "# --- 2. Wrap back as DataFrames (optional, for better column tracking) ---\n",
    "X_train_transform_scaled = pd.DataFrame(X_train_transform_scaled, columns=X_train_transform.columns, index=X_train_transform.index)\n",
    "X_val_transform_scaled = pd.DataFrame(X_val_transform_scaled, columns=X_val_transform.columns, index=X_val_transform.index)\n",
    "X_test_transform_scaled = pd.DataFrame(X_test_transform_scaled, columns=X_test_transform.columns, index=X_test_transform.index)\n",
    "\n",
    "X_train_no_transform_scaled = pd.DataFrame(X_train_no_transform_scaled, columns=X_train_no_transform.columns, index=X_train_no_transform.index)\n",
    "X_val_no_transform_scaled = pd.DataFrame(X_val_no_transform_scaled, columns=X_val_no_transform.columns, index=X_val_no_transform.index)\n",
    "X_test_no_transform_scaled = pd.DataFrame(X_test_no_transform_scaled, columns=X_test_no_transform.columns, index=X_test_no_transform.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Validation/Test datasets with scaling saved.\n"
     ]
    }
   ],
   "source": [
    "X_train_transform_scaled.to_csv(\"../../data/processed/transformed/X_train_transform_scaled.csv\", index=False)\n",
    "X_val_transform_scaled.to_csv(\"../../data/processed/transformed/X_val_transform_scaled.csv\", index=False)\n",
    "X_test_transform_scaled.to_csv(\"../../data/processed/transformed/X_test_transform_scaled.csv\", index=False)\n",
    "\n",
    "X_train_no_transform_scaled.to_csv(\"../../data/processed/no_transformed/X_train_no_transform_scaled.csv\", index=False)\n",
    "X_val_no_transform_scaled.to_csv(\"../../data/processed/no_transformed/X_val_no_transform_scaled.csv\", index=False)\n",
    "X_test_no_transform_scaled.to_csv(\"../../data/processed/no_transformed/X_test_no_transform_scaled.csv\", index=False)\n",
    "\n",
    "print(\"Train/Validation/Test datasets with scaling saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the RobustScaler on training data, we save the scaler object using joblib.\n",
    "This ensures consistency during testing and future predictions, preventing data leakage and scaling mismatches.\n",
    "Separate scalers are stored for the log-transformed and non-transformed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalers saved.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "SCALER_DIR = \"../../models/\"\n",
    "os.makedirs(SCALER_DIR, exist_ok=True)\n",
    "\n",
    "# store scaler with log version\n",
    "joblib.dump(scaler_transform, os.path.join(SCALER_DIR, \"robust_scaler_transform.pkl\"))\n",
    "\n",
    "# storescaler_no_transform（without log version）\n",
    "joblib.dump(scaler_no_transform, os.path.join(SCALER_DIR, \"robust_scaler_no_transform.pkl\"))\n",
    "\n",
    "print(\"Scalers saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
